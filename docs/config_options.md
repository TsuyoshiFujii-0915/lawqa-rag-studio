# Config Options

> This document is auto-generated by tools/generate_config_docs.py.
> Do not edit manually.

| Path | Option | Description | Default |
|------|--------|-------------|---------|
| `chunking.strategy` | `fixed` | Sliding window with fixed size chunks | ✓ |
| `chunking.strategy` | `hierarchy` | Structure-aware chunking |  |
| `chunking.hierarchy.level` | `law` | Entire law as one chunk |  |
| `chunking.hierarchy.level` | `suppl_provision` | Chunk per supplementary provision block |  |
| `chunking.hierarchy.level` | `chapter` | Chunk per chapter |  |
| `chunking.hierarchy.level` | `section` | Chunk per section | ✓ |
| `chunking.hierarchy.level` | `subsection` | Chunk per subsection |  |
| `chunking.hierarchy.level` | `division` | Chunk per division |  |
| `chunking.hierarchy.level` | `article` | Chunk per article |  |
| `chunking.hierarchy.level` | `paragraph` | Chunk per paragraph |  |
| `embedding.dense.model` | `text-embedding-3-small` | OpenAI small embedding model (1536-dim) | ✓ |
| `embedding.dense.model` | `text-embedding-3-large` | OpenAI large embedding model (3072-dim) |  |
| `embedding.sparse.model` | `bizreach-inc/light-splade-japanese-56M` | Japanese-oriented lightweight SPLADE model | ✓ |
| `retriever.hybrid.combine` | `rrf` | Reciprocal Rank Fusion | ✓ |
| `retriever.hybrid.combine` | `linear` | Normalized linear combination |  |
| `retriever.rerank.model` | `BAAI/bge-reranker-v2-m3` | Multilingual reranker | ✓ |
| `retriever.rerank.model` | `hotchpotch/japanese-bge-reranker-v2-m3-v1` | Japanese-specific reranker |  |
| `llm.provider` | `openai` | OpenAI API | ✓ |
| `llm.provider` | `lmstudio` | LM Studio OpenAI-compatible API |  |
| `llm.model` | `gpt-5.2` | Latest GPT-5.2 |  |
| `llm.model` | `gpt-5.1` | GPT-5.1 |  |
| `llm.model` | `gpt-5` | GPT-5 |  |
| `llm.model` | `gpt-5-mini` | Lightweight GPT-5 Mini | ✓ |
| `llm.model` | `gpt-5-nano` | Smallest GPT-5 Nano |  |
| `llm.model` | `openai/gpt-oss-20b` | 20B OSS model via LM Studio |  |
| `llm.openai.rag_mode` | `plain` | Classic RAG: context stuffed into prompt | ✓ |
| `llm.openai.rag_mode` | `agentic` | Agentic RAG: retrieve as tool for the model |  |
| `logging.level` | `DEBUG` | Verbose debug logging |  |
| `logging.level` | `INFO` | Standard info logging | ✓ |
| `logging.level` | `WARNING` | Warnings only |  |
| `logging.level` | `ERROR` | Errors only |  |
